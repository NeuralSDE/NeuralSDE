dataset:
  denoising: true
  in_latent_space: false
  name: branching
  noise_std: 0.0
  obs_horizon: 1
  time_gap: 1.0
  use_hermite_spline: false
eval:
  denoiser_path: ./runs/branching/original_d/20250313-052605/denoiser_ep_100.pth
  denoising_magnitude: 1.0
  diffusion_magnitide: 1.0
  diffusion_path: ./runs/branching/original_g/20250313-052846/diffusion_ep_140.pth
  flow_path: ./runs/branching/original_f/20250313-052251/flow_ep_120.pth
  num_eval_runs: 10
  num_points: 100
  num_trajectories: 10
  use_sde: true
  visualize_trajectory: true
training:
  batch_size: 256
  checkpoint_interval: 20
  denoiser:
    factor: 0.5
    hidden_dim: 128
    l2_reg: 0
    learning_rate: 0.0002
    loss_fn: mse
    multi_noise: false
    noise_std: 0.1
    norm_type: layer
    num_layers: 5
    optimizer: adam
    patience: 10
    resume: false
    resume_epoch: 0
    resume_run_path: ''
    train_denoiser: true
    use_learning_schedule: true
  diffusion:
    factor: 0.5
    flow_path: ./runs/branching/original_f/20250313-052251/flow_ep_120.pth
    hidden_dim: 128
    l2_reg: 0
    learning_rate: 4.0e-05
    logit_max: -2.5
    logit_min: -7.5
    multi_noise: false
    noise_std: 0.1
    norm_type: layer
    num_layers: 5
    optimizer: adam
    patience: 10
    resume: false
    resume_epoch: 0
    resume_run_path: ''
    train_diffusion: true
    train_on_clean_data: true
    use_learning_schedule: true
  flow:
    desingularization: None
    factor: 0.5
    hidden_dim: 128
    l2_reg: 0
    learning_rate: 0.0002
    loss_fn: mse
    multi_noise: false
    noise_std: 0.1
    norm_type: layer
    num_layers: 5
    optimizer: adam
    patience: 10
    resume: false
    resume_epoch: 0
    resume_run_path: ''
    train_flow: true
    train_on_clean_data: false
    use_learning_schedule: true
  log_dir_base: ./runs
  mixed_precision: false
  num_epochs: 200
  save_model: true
  seed: 42
  val_split: 0.1
